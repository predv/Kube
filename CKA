Kubernetes - K8s

Cluster
Nodes:
  Worker Node: сервера на которых работают контейнеры
  Master Node: сервер котрый управлчем Worker Node

  Процессы которые крутяться на Master Node и Worker Node
  Master Node:
    kube-apisrever
    kube-controller-manager
    kube-schuduler
  Worker Node:
    kublet
    kube-proxy

    Кластер состоит из Master Node и много Worket Node
    Загружаються Docker Image в кластер из: DockerHub
                                          : AWS
                                          : Google
                                          : Azure

  Что может Kubernetes и почему он популярен
  1. Service discovery and load balancing: создает через IP адрес с определенным портом или DNS имя, и балансирует подключение внутри кластера.
  2. Storage orchestraion:
---------------------------------------------------------

API SERVER  -   Authenticare User(),
                Validate Request(проверка запроса),
                Retrieve Data(извлечение данных),
                Update ETCD,
                Scheduler,
                Kubelet
/etc/kubernetes/manifests/kube-apiserver.yaml
/etc/systemd/system/kube-apiserver.service
ps -ax | grep kube-apiserver

Controllers  -  Watch status,
                Remediate Situation
                Node Monitor Period = 5s
                Node Monitor Grace Period = 40s
                POD Eviction Timeout = 5min
/etc/kubernetes/manifests/kube-controller-manager.yaml
/etc/systemd/system/kube-controller-manager.yaml
ps -ax | grep kube-controller-manager

KUBE SCHEDULER -  Логист распределения задач
/etc/kubernetes/manifests/kube-scheduler.yaml

KUBELET    -  ответственный за NODE
              Register Node
              Create PODs
              Monitoring Node & PODs
/etc/kubernetes/kublete.conf
ps -ax | grep kubelete
УСТАНАВЛИВАЕТСЯ ВСЕГДА ОТДЕЛЬНО БЕЗ 

KUBE PROXY  -   POD NETWORK

PODs        -  kubctl run nginx - создание PODs из реопзитория или из приватного github
            -  kubctl get pods - полчить информацию о PODs
  YAML: всегда содержит 4 поля
  apiVersion: версия API kubernetes: v1, apps/v1
  kind: тип объекта: Pod, Service, ReplicaSet, Deployment
  metadata: данные об объекте:
    name: myapp-pod
    labels: 
      app: myapp
      type: front-end
  spec:
    containers:
      name: nginx-container
      image: nginx
Команда для создания POD с контейнером: kubectl -f pod-definition.yml
kubectl get pods
kubectl describe pod (имя POD)

Реплики
Гарантированная поддержка в работе PODs и балансировка нагрузки на Node
    Replication controller  -
    Replica Set             -

Создание контролера rc-definition.yml

Replication controller
apiVersion: v1
kind: ReplicationController
metadata: 
  name: myapp-rc
  labels:
    app: myapp
    type: frond-end
spec:
  template:
    metadata:
      name: myapp-pod
      labels: 
        app: myapp
        type: front-end
    spec:
      containers:
      - name: nginx-container
        image: nginx
  replicas: 3
> kubectl create -f rc-definition.yml
> kubectl get replicationcontroller
> kubectl get pods

Replica SET
apiVersion: apps/v1
kind: ReplicaSet
metadata: 
  name: myapp-rc
  labels:
    app: myapp
    type: frond-end
spec:
  template:
    metadata:
      name: myapp-pod
      labels: 
        app: myapp
        type: front-end
    spec:
      containers:
      - name: nginx-container
        image: nginx
  replicas: 3
  selector: (перечисление нужных PODs с помощью matchLabels)
    matchLabels:
      type: front-end

Метки и селекторы:
replicaSet использует selector:             metadata:для отслеживания их состояния
                        matchLabels:          name: myapp-pod
                          tier: front-end     labels:
                                                tier: front-end
Увеличение кол-во реплик, два варианта:
Изменяем парметр replicas: 6 
Вариант 1:
вводим команду kubctl replace -f replicaset-definition.yml

Вариант 2:
kubctl scale --replicas=6 -f replicaset-definition.yml

Динамический вариант:
kubctl scale --replicas=6 replicaset myapp-replicaset

> Команды:
> kubectr create -f Файл.yml
> kubectr get replicaset
> kubectr delete replicaset myapp-replicaset
> kubectr replace -f Файл.yml
> kubectr scale --replicas=6 replicaset myapp-replicaset - увеличение кол-во PODs
> kubectl deployment - развертывание
> kubectl get all - отображение всех объектов за один раз
> kubectl get pods --namespace=kube-system - просмотр PODs в другом пространстве
> kubectl create -f (файл).yml --namespace=dev - создание POD в другом пространстве имен
> kubectl config set-context $(kubectl config current-context) --namespace=dev
> kubectl get pods --all-namespaces
> kubectl get pods --A
-----------------------------------------------------------
Deployment Деплоймент:
apiVersion: apps/v1
kind: Deployment
metadata: 
  name: myapp-deloyment
  labels:
    app: myapp
    type: frond-end
spec:
  template:
    metadata:
      name: myapp-pod
      labels: 
        app: myapp
        type: front-end
    spec:
      containers:
      - name: nginx-container
        image: nginx
  replicas: 3
  selector:
    matchLabels:
      type: front-end
---------------------------------------------------------------
NAMESPACE пространство имен:
default      -  
kube-system  -  пространство для системных компонентов
kube-public  -  ресурсы для всех 
можно создавать пространства и выделать квоты на использование ресурсов
опимание адресной ссылки на ресурсы db-service(название сервиса).dev(название пространства).svc(поддомен для сервиса).cluster.local(название домена)
В описание файл .yml в разделе  metadata:        добавляется параметр namespace: dev с указание имени пространства
                                  namespace: dev  
Создание NAMESPACE пространства имен:
namespace-dev.yml
apiVersion: v1
kind: Namespace
metadata:
  name: dev
> kubectl create -f namespace-dev.yml
> kubectl create namespace dev
Как переключаться между пространствами:
> kubectl config set-context $(kubectl config current-context) --namespace=dev
Квоты ресурсов:
compute-quota.yml
apiVersion: v1
kind: ResourseQuota
metadata: 
  name: compute-quota
  namespace: dev
spec:
  hard:
    pods: "10"
    requests.cpu: "4"
    requests.memory: 5Gi
    limits.cpu: "10"
    limits.memory: 10Gi
------------------------------------------------------------

SERVICE службы:
NodePort  -  TargetPort - конечная цель запроса, целевой порт; Port - середина пути; NodePort - начало запроса, диапазон 30000-32767
ClusterIP  -  
LoadBalancer  -

NodePort:
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
spec:
  type: NodePort
  ports:
  -  targetPort: 80
     port: 80
     nodePort: 30008
